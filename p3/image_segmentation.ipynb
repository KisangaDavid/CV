{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgO0k03dlZ-T"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this assignment, you will practice building and training Convolutional Neural Networks with Pytorch to solve computer vision tasks.  This assignment includes two sections, each involving different tasks:\n",
        "\n",
        "(1) Image Classification. Predict image-level category labels on two historically notable image datasets: **CIFAR-10** and **MNIST**.\n",
        "\n",
        "(2) Image Segmentation. Predict pixel-wise classification (semantic segmentation) on synthetic input images formed by superimposing MNIST images on top of CIFAR images.\n",
        "\n",
        "You will design your own models in each section and build the entire training/testing pipeline with PyTorch. \n",
        "PyTorch provides optimized implementations of the building blocks and additional utilities, both of which will be necessary for experiments on real datasets. It is highly recommended to read the official [documentation](https://pytorch.org/docs/stable/index.html) and [examples](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) before starting your implementation. There are some APIs that you'll find useful:\n",
        "[Layers](http://pytorch.org/docs/stable/nn.html),\n",
        "[Activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity),\n",
        "[Loss functions](http://pytorch.org/docs/stable/nn.html#loss-functions),\n",
        "[Optimizers](http://pytorch.org/docs/stable/optim.html)\n",
        "\n",
        "It is highly recommended to use Google Colab and run the notebook on a GPU node. Check https://colab.research.google.com/ and look for tutorials online. To use a GPU go to Runtime -> Change runtime type and select GPU. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5lueGqqw6sR"
      },
      "source": [
        "# (2) Image Segmentation\n",
        "The task consists of performing pixel-wise classification on a synthetic dataset\n",
        "of 32x32 RGB images. Each image was generated by placing a MNIST sample (a grayscale\n",
        "image of a digit between 0 and 9) on top of a CIFAR-10 sample (a RGB image drawn from\n",
        "one of 10 possible classes). Each image has an accompanying target tensor of size 32x32,\n",
        "where in each pixel location (i,j) it contains the ground-truth label of the MNIST digit\n",
        "(ranging from 0 to 9) or of the CIFAR-10 image (ranging from 10 to 19), depending on whether\n",
        "the (i,j) pixel in the original image belongs to the superposed MNIST image or not. The\n",
        "metric of interest here is pixel-wise accuracy, which is the fraction of pixels in each image\n",
        "for which your model predicted the correct class (out of a total of 20 classes, as described \n",
        "above).\n",
        "\n",
        "Note that there are many ways to frame the above task. For example, your CNN can directly\n",
        "output a 20x32x32 tensor for each input image, representing a distribution over the possible\n",
        "20 classes for each of the 32x32 pixels. However, note that the problem has a lot of additional\n",
        "structure: for example, each 32x32 target tensor only has two distinct numbers in it, the label\n",
        "of the MNIST digit and the label of the CIFAR-10 background image -- accounting for such\n",
        "structure will make training faster and likely improve your model's final performance. Your\n",
        "model should be able to achieve around 70% accuracy on the test set when trained for 100 epochs.\n",
        "\n",
        "To finish this section step by step, you need to:\n",
        "\n",
        "* Prepare data by building a dataset and data loader. (already provided below)\n",
        "\n",
        "* Implement training code (6 points) & testing code (6 points), including saving and loading of models.\n",
        "\n",
        "* Construct a model (12 points) and choose an optimizer (3 points).\n",
        "\n",
        "* Describe what you did, any additional features you implemented, and/or any graphs you made in training and evaluating your network. Report final test accuracy @100 epochs in a writeup: hw3.pdf (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2nAlwqqFzLfU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "from utils import SegDataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpFf3VOO1bT1"
      },
      "source": [
        "## Data Preparation:\n",
        "\n",
        "Setup a Dataset for training and testing.\n",
        "\n",
        "Datasets load single training examples one a time, so we practically wrap each Dataset in a DataLoader, which loads a data batch in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R_6rGLHwzMxp"
      },
      "outputs": [],
      "source": [
        "seg_train = SegDataset('./data', train=True, transform=None)\n",
        "loader_train = DataLoader(seg_train, batch_size=64, shuffle=True)\n",
        "seg_test = SegDataset('./data', train=False, transform=None)\n",
        "loader_test = DataLoader(seg_test, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def visualize_samples(dataset, num_samples):\n",
        "    for _ in range(num_samples):\n",
        "        random_seg_img = random.randint(0, len(dataset))\n",
        "        x, y = dataset[random_seg_img]\n",
        "        plt.imshow(x.permute(1, 2, 0))\n",
        "        plt.title(f\"Training example #{random_seg_img}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "visualize_samples(seg_train, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58GUecr83BmH"
      },
      "source": [
        "## Design/choose your own model structure (12 points) and optimizer (3 points).\n",
        "You might want to adjust following configurations for better performance:\n",
        "\n",
        "(1) Network architecture:\n",
        "- You can borrow some ideas from existing convnets design, e.g., [ResNet](https://arxiv.org/abs/1512.03385) where\n",
        "the input from the previous layer is added to the output, or [UNet](https://arxiv.org/pdf/1505.04597.pdf) where you can stack intermediate features from previous layers. \n",
        "- Note: Do not **directly copy** an existing network design.\n",
        "\n",
        "(2) Architecture hyperparameters:\n",
        "- Filter size, number of filters, and number of layers (depth). Make careful choices to tradeoff computational efficiency and accuracy.\n",
        "- Pooling vs. Strided Convolution\n",
        "- Batch normalization\n",
        "- Choice of non-linear activation\n",
        "\n",
        "(3) Choice of optimizer (e.g., SGD, Adam, Adagrad, RMSprop) and associated hyperparameters (e.g., learning rate, momentum).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ZA5kw3X3qLy"
      },
      "outputs": [],
      "source": [
        "#Basic model, feel free to customize the layout to fit your model design.\n",
        "\n",
        "##########################################################################\n",
        "# TODO: YOUR CODE HERE\n",
        "# (1) Complete the model\n",
        "##########################################################################\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(myNet, self).__init__()\n",
        "        \n",
        "        # batch normalization = bad, https://arxiv.org/abs/1903.07291\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encodeLayer1 = nn.Conv2d(3, 64, 3, padding = 1) # 32 x 32 x 64\n",
        "        self.encodeLayer2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        # After max pooling, output will be 16 x 16 x 64\n",
        "\n",
        "        self.encodeLayer3 = nn.Conv2d(64, 128, 3, padding = 1) # 16 x 16 x 128\n",
        "        self.encodeLayer4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        # After max pooling, output will be 8 x 8 x 128\n",
        "\n",
        "        self.encodeLayer5 = nn.Conv2d(128, 256, 3, padding = 1) # 32 x 32 x 32\n",
        "        self.encodeLayer6 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        # After max pooling, output will be 4 x 4 x 256\n",
        "\n",
        "        self.encodeLayer7 = nn.Conv2d(256, 512, 3, padding = 1) # 4 x 4 x 512\n",
        "        self.encodeLayer8 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        # After max pooling, output will be 2 x 2 x 512\n",
        "        \n",
        "        self.encodeLayer9 = nn.Conv2d(512, 1024, 3, padding = 1) # 32 x 32 x 32\n",
        "        self.encodeLayer10 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decodeUpConv1 = nn.ConvTranspose2d(1024, 512, 2, 2)\n",
        "        self.decodeLayerConv1 = nn.Conv2d(1024, 512, 3, padding=1)\n",
        "        self.decodeLayerConv2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "\n",
        "        self.decodeUpConv2 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
        "        self.decodeLayerConv3 = nn.Conv2d(512, 256, 3, padding=1)\n",
        "        self.decodeLayerConv4 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "\n",
        "        self.decodeUpConv3 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "        self.decodeLayerConv5 = nn.Conv2d(256, 128, 3, padding=1)\n",
        "        self.decodeLayerConv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "\n",
        "        self.decodeUpConv4 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.decodeLayerConv7 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.decodeLayerConv8 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "\n",
        "        self.out = nn.Conv2d(64, 20, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder steps, results must be saved for decoder steps:\n",
        "        encodeLayer1 = self.dropout(F.relu(self.encodeLayer1(x)))\n",
        "        encodeLayer2 = F.relu(self.encodeLayer2(encodeLayer1))\n",
        "        pool1 = self.pool(encodeLayer2)\n",
        "\n",
        "        encodeLayer3 = self.dropout(F.relu(self.encodeLayer3(pool1)))\n",
        "        encodeLayer4 = F.relu(self.encodeLayer4(encodeLayer3))\n",
        "        pool2 = self.pool(encodeLayer4)\n",
        "\n",
        "        encodeLayer5 = self.dropout(F.relu(self.encodeLayer5(pool2)))\n",
        "        encodeLayer6 = F.relu(self.encodeLayer6(encodeLayer5))\n",
        "        pool3 = self.pool(encodeLayer6)\n",
        "\n",
        "        encodeLayer7 = self.dropout(F.relu(self.encodeLayer7(pool3)))\n",
        "        encodeLayer8 = F.relu(self.encodeLayer8(encodeLayer7))\n",
        "        pool4 = self.pool(encodeLayer8)\n",
        "\n",
        "        encodeLayer9 = self.dropout(F.relu(self.encodeLayer9(pool4)))\n",
        "        encodeLayer10 = F.relu(self.encodeLayer10(encodeLayer9))\n",
        "\n",
        "        # Decoder steps, use results from encoder steps\n",
        "        decodeUpConv1 = self.dropout(self.decodeUpConv1(encodeLayer10))\n",
        "        decodeLayer1 = F.relu(self.decodeLayerConv1(torch.cat([decodeUpConv1,encodeLayer8], dim=1)))\n",
        "        decodeLayer2 = F.relu(self.decodeLayerConv2(decodeLayer1))\n",
        "\n",
        "        decodeUpConv2 = self.dropout(self.decodeUpConv2(decodeLayer2))\n",
        "        decodeLayer3 = F.relu(self.decodeLayerConv3(torch.cat([decodeUpConv2, encodeLayer6], dim = 1)))\n",
        "        decodeLayer4 = F.relu(self.decodeLayerConv4(decodeLayer3))\n",
        "\n",
        "        decodeUpConv3 = self.dropout(self.decodeUpConv3(decodeLayer4))\n",
        "        decodeLayer5 = F.relu(self.decodeLayerConv5(torch.cat([decodeUpConv3, encodeLayer4], dim = 1)))\n",
        "        decodeLayer6 = F.relu(self.decodeLayerConv6(decodeLayer5))\n",
        "\n",
        "        decodeUpConv4 = self.dropout(self.decodeUpConv4(decodeLayer6))\n",
        "        decodeLayer7 = F.relu(self.decodeLayerConv7(torch.cat([decodeUpConv4, encodeLayer2], dim = 1)))\n",
        "        decodeLayer8 = F.relu(self.decodeLayerConv8(decodeLayer7))\n",
        "\n",
        "        \n",
        "\n",
        "        return self.out(decodeLayer8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOuB58GA5W_C"
      },
      "source": [
        "## Training (6 points)\n",
        "\n",
        "Train a model on the given dataset using the PyTorch Module API.\n",
        "\n",
        "Inputs:\n",
        "- loader_train: The loader from which train samples will be drawn from.\n",
        "- loader_test: The loader from which test samples will be drawn from\n",
        "- model: A PyTorch Module giving the model to train.\n",
        "- optimizer: An Optimizer object we will use to train the model\n",
        "- epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "Returns: Nothing, but prints model accuracies during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0Kx_q5rv5ddg"
      },
      "outputs": [],
      "source": [
        "def validation_split_from_loader(loader_train):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for _, (x,y) in enumerate(loader_train):\n",
        "        features.append(x)\n",
        "        labels.append(y)\n",
        "    all_features = torch.cat(features)\n",
        "    all_labels = torch.cat(labels)\n",
        "    train_dataset = torch.utils.data.TensorDataset(all_features, all_labels)\n",
        "    train_set, val_set = random_split(train_dataset, [int(0.9 * len(train_dataset)), int(0.1 * len(train_dataset))])\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "    val_data_loader = torch.utils.data.DataLoader(val_set,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "    return train_data_loader, val_data_loader\n",
        "\n",
        "def validate(loader_validation, model, device):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    num_samples = 0\n",
        "    num_pixels_correct = 0\n",
        "    for t, (x,y) in enumerate(loader_validation):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # For validation using loss:\n",
        "        # loss = F.cross_entropy(model(x), y)\n",
        "        num_samples += x.size()[0]\n",
        "        outputs = model(x)\n",
        "        outputs = torch.argmax(outputs,1)\n",
        "        num_pixels_correct += torch.eq(outputs,y).sum()\n",
        "\n",
        "    return (num_pixels_correct / (num_samples * 32 * 32)) * 100\n",
        "\n",
        "def train(loader_train, loader_test, model, optimizer, model_name, epochs=100):\n",
        "    loader_train, loader_val = validation_split_from_loader(loader_train)\n",
        "    # Working locally on laptop and desktop, sometimes no gpu available. Device is gpu if gpu is available, cpu otherwise\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    prevValAcc = None\n",
        "    bestModelStateDict = None\n",
        "    num_times_val_decreased = 0\n",
        "    for e in range(epochs):\n",
        "        model.train()\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
        "       \n",
        "        valAcc = validate(loader_val, model, device)\n",
        "        print(f\"validation accuracy on validation set: {valAcc}\")\n",
        "        if prevValAcc == None:\n",
        "            prevValAcc = valAcc\n",
        "            bestModelStateDict = model.state_dict()\n",
        "            continue\n",
        "\n",
        "        # Early stopping condition\n",
        "        if valAcc < prevValAcc:\n",
        "             num_times_val_decreased += 1\n",
        "             if num_times_val_decreased > 5:\n",
        "                print(f\"EARLY STOP DUE TO DECREASED VALIDATION ACCURACY: USING MODEL AT EPOCH {e - num_times_val_decreased}\")\n",
        "                print(f\"best model validation accuracy: {prevValAcc}\")\n",
        "                break\n",
        "        else:\n",
        "            prevValAcc = valAcc\n",
        "            bestModelStateDict = model.state_dict()\n",
        "            num_times_val_decreased = 0\n",
        "    # saving model \n",
        "    torch.save(bestModelStateDict, model_name + '.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdxEMZpC6E9K"
      },
      "source": [
        "## Testing (6 points)\n",
        "Test a model using the PyTorch Module API.\n",
        "\n",
        "Inputs:\n",
        "- loader: The loader from which test samples will be drawn from.\n",
        "- model: A PyTorch Module giving the model to test.\n",
        "\n",
        "Returns: Nothing, but prints model accuracies during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KA5YBjxx6IeF"
      },
      "outputs": [],
      "source": [
        "def test(loader, model, model_name):\n",
        "    model.load_state_dict(torch.load(model_name + '.pth'))\n",
        "    num_pixels_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            num_samples += x.size()[0]\n",
        "            outputs = torch.argmax(model(x),1)\n",
        "            num_pixels_correct += (outputs == y).sum().item()\n",
        "            \n",
        "    acc = num_pixels_correct / (num_samples * 32 * 32)\n",
        "    print('Eval %d pixels / %d pixels correct (%.2f)' % (num_pixels_correct, num_samples * 32 * 32, 100 * acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omwoZPA26V-a"
      },
      "source": [
        "Describe your design details in the writeup hw3.pdf. (3 points)\n",
        "\n",
        "Finish your model and optimizer below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jM6GIIFP6XhG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch 0, Iteration 0, loss = 3.0027\n",
            "Epoch 0, Iteration 100, loss = 2.4387\n",
            "Epoch 0, Iteration 200, loss = 2.2617\n",
            "Epoch 0, Iteration 300, loss = 2.2051\n",
            "Epoch 0, Iteration 400, loss = 2.1924\n",
            "Epoch 0, Iteration 500, loss = 2.1544\n",
            "Epoch 0, Iteration 600, loss = 2.0745\n",
            "Epoch 0, Iteration 700, loss = 2.0386\n",
            "validation accuracy on validation set: 22.751543045043945\n",
            "Epoch 1, Iteration 0, loss = 2.0640\n",
            "Epoch 1, Iteration 100, loss = 1.9845\n",
            "Epoch 1, Iteration 200, loss = 1.8809\n",
            "Epoch 1, Iteration 300, loss = 1.9804\n",
            "Epoch 1, Iteration 400, loss = 1.9037\n",
            "Epoch 1, Iteration 500, loss = 2.0196\n",
            "Epoch 1, Iteration 600, loss = 1.8547\n",
            "Epoch 1, Iteration 700, loss = 1.8805\n",
            "validation accuracy on validation set: 27.653614044189453\n",
            "Epoch 2, Iteration 0, loss = 1.9179\n",
            "Epoch 2, Iteration 100, loss = 1.8177\n",
            "Epoch 2, Iteration 200, loss = 1.8116\n",
            "Epoch 2, Iteration 300, loss = 1.8523\n",
            "Epoch 2, Iteration 400, loss = 1.8335\n",
            "Epoch 2, Iteration 500, loss = 1.8004\n",
            "Epoch 2, Iteration 600, loss = 1.9670\n",
            "Epoch 2, Iteration 700, loss = 1.7084\n",
            "validation accuracy on validation set: 35.07872772216797\n",
            "Epoch 3, Iteration 0, loss = 1.7103\n",
            "Epoch 3, Iteration 100, loss = 1.5871\n",
            "Epoch 3, Iteration 200, loss = 1.8088\n",
            "Epoch 3, Iteration 300, loss = 1.9217\n",
            "Epoch 3, Iteration 400, loss = 1.7533\n",
            "Epoch 3, Iteration 500, loss = 1.6179\n",
            "Epoch 3, Iteration 600, loss = 1.7262\n",
            "Epoch 3, Iteration 700, loss = 1.6847\n",
            "validation accuracy on validation set: 39.89814376831055\n",
            "Epoch 4, Iteration 0, loss = 1.4927\n",
            "Epoch 4, Iteration 100, loss = 1.5346\n",
            "Epoch 4, Iteration 200, loss = 1.6041\n",
            "Epoch 4, Iteration 300, loss = 1.6181\n",
            "Epoch 4, Iteration 400, loss = 1.5346\n",
            "Epoch 4, Iteration 500, loss = 1.7770\n",
            "Epoch 4, Iteration 600, loss = 1.7441\n",
            "Epoch 4, Iteration 700, loss = 1.5402\n",
            "validation accuracy on validation set: 42.83601379394531\n",
            "Epoch 5, Iteration 0, loss = 1.5139\n",
            "Epoch 5, Iteration 100, loss = 1.4031\n",
            "Epoch 5, Iteration 200, loss = 1.5122\n",
            "Epoch 5, Iteration 300, loss = 1.6513\n",
            "Epoch 5, Iteration 400, loss = 1.6238\n",
            "Epoch 5, Iteration 500, loss = 1.6718\n",
            "Epoch 5, Iteration 600, loss = 1.7241\n",
            "Epoch 5, Iteration 700, loss = 1.5303\n",
            "validation accuracy on validation set: 44.85759735107422\n",
            "Epoch 6, Iteration 0, loss = 1.5613\n",
            "Epoch 6, Iteration 100, loss = 1.5044\n",
            "Epoch 6, Iteration 200, loss = 1.3655\n",
            "Epoch 6, Iteration 300, loss = 1.4776\n",
            "Epoch 6, Iteration 400, loss = 1.3716\n",
            "Epoch 6, Iteration 500, loss = 1.5403\n",
            "Epoch 6, Iteration 600, loss = 1.3551\n",
            "Epoch 6, Iteration 700, loss = 1.3643\n",
            "validation accuracy on validation set: 48.016170501708984\n",
            "Epoch 7, Iteration 0, loss = 1.3399\n",
            "Epoch 7, Iteration 100, loss = 1.4541\n",
            "Epoch 7, Iteration 200, loss = 1.2550\n",
            "Epoch 7, Iteration 300, loss = 1.4317\n",
            "Epoch 7, Iteration 400, loss = 1.2720\n",
            "Epoch 7, Iteration 500, loss = 1.2691\n",
            "Epoch 7, Iteration 600, loss = 1.4231\n",
            "Epoch 7, Iteration 700, loss = 1.4730\n",
            "validation accuracy on validation set: 49.62827682495117\n",
            "Epoch 8, Iteration 0, loss = 1.2500\n",
            "Epoch 8, Iteration 100, loss = 1.5748\n",
            "Epoch 8, Iteration 200, loss = 1.2548\n",
            "Epoch 8, Iteration 300, loss = 1.4326\n",
            "Epoch 8, Iteration 400, loss = 1.3022\n",
            "Epoch 8, Iteration 500, loss = 1.3693\n",
            "Epoch 8, Iteration 600, loss = 1.3520\n",
            "Epoch 8, Iteration 700, loss = 1.3260\n",
            "validation accuracy on validation set: 50.91607666015625\n",
            "Epoch 9, Iteration 0, loss = 1.2219\n",
            "Epoch 9, Iteration 100, loss = 1.2299\n",
            "Epoch 9, Iteration 200, loss = 1.4857\n",
            "Epoch 9, Iteration 300, loss = 1.3627\n",
            "Epoch 9, Iteration 400, loss = 1.1880\n",
            "Epoch 9, Iteration 500, loss = 1.4265\n",
            "Epoch 9, Iteration 600, loss = 1.4760\n",
            "Epoch 9, Iteration 700, loss = 1.6705\n",
            "validation accuracy on validation set: 51.67787170410156\n",
            "Epoch 10, Iteration 0, loss = 1.3607\n",
            "Epoch 10, Iteration 100, loss = 1.1827\n",
            "Epoch 10, Iteration 200, loss = 1.1598\n",
            "Epoch 10, Iteration 300, loss = 1.1062\n",
            "Epoch 10, Iteration 400, loss = 1.1683\n",
            "Epoch 10, Iteration 500, loss = 1.1553\n",
            "Epoch 10, Iteration 600, loss = 1.3118\n",
            "Epoch 10, Iteration 700, loss = 1.1423\n",
            "validation accuracy on validation set: 55.4025764465332\n",
            "Epoch 11, Iteration 0, loss = 1.0320\n",
            "Epoch 11, Iteration 100, loss = 1.2105\n",
            "Epoch 11, Iteration 200, loss = 1.2232\n",
            "Epoch 11, Iteration 300, loss = 1.1333\n",
            "Epoch 11, Iteration 400, loss = 1.2738\n",
            "Epoch 11, Iteration 500, loss = 1.3475\n",
            "Epoch 11, Iteration 600, loss = 1.1920\n",
            "Epoch 11, Iteration 700, loss = 1.4434\n",
            "validation accuracy on validation set: 57.447654724121094\n",
            "Epoch 12, Iteration 0, loss = 0.9005\n",
            "Epoch 12, Iteration 100, loss = 1.0647\n",
            "Epoch 12, Iteration 200, loss = 1.0757\n",
            "Epoch 12, Iteration 300, loss = 1.1574\n",
            "Epoch 12, Iteration 400, loss = 1.1254\n",
            "Epoch 12, Iteration 500, loss = 1.0293\n",
            "Epoch 12, Iteration 600, loss = 1.2374\n",
            "Epoch 12, Iteration 700, loss = 1.0485\n",
            "validation accuracy on validation set: 57.209022521972656\n",
            "Epoch 13, Iteration 0, loss = 0.9957\n",
            "Epoch 13, Iteration 100, loss = 1.0952\n",
            "Epoch 13, Iteration 200, loss = 1.0930\n",
            "Epoch 13, Iteration 300, loss = 1.0263\n",
            "Epoch 13, Iteration 400, loss = 1.1275\n",
            "Epoch 13, Iteration 500, loss = 1.2495\n",
            "Epoch 13, Iteration 600, loss = 1.0242\n",
            "Epoch 13, Iteration 700, loss = 0.9426\n",
            "validation accuracy on validation set: 56.92203140258789\n",
            "Epoch 14, Iteration 0, loss = 1.2301\n",
            "Epoch 14, Iteration 100, loss = 1.0887\n",
            "Epoch 14, Iteration 200, loss = 0.8231\n",
            "Epoch 14, Iteration 300, loss = 1.1164\n",
            "Epoch 14, Iteration 400, loss = 1.1466\n",
            "Epoch 14, Iteration 500, loss = 1.0562\n",
            "Epoch 14, Iteration 600, loss = 1.2131\n",
            "Epoch 14, Iteration 700, loss = 1.3118\n",
            "validation accuracy on validation set: 54.743553161621094\n",
            "Epoch 15, Iteration 0, loss = 1.1397\n",
            "Epoch 15, Iteration 100, loss = 0.9924\n",
            "Epoch 15, Iteration 200, loss = 1.1401\n",
            "Epoch 15, Iteration 300, loss = 1.0013\n",
            "Epoch 15, Iteration 400, loss = 0.9369\n",
            "Epoch 15, Iteration 500, loss = 1.1637\n",
            "Epoch 15, Iteration 600, loss = 1.1161\n",
            "Epoch 15, Iteration 700, loss = 1.2576\n",
            "validation accuracy on validation set: 59.82228469848633\n",
            "Epoch 16, Iteration 0, loss = 1.0476\n",
            "Epoch 16, Iteration 100, loss = 1.0927\n",
            "Epoch 16, Iteration 200, loss = 1.0101\n",
            "Epoch 16, Iteration 300, loss = 1.2049\n",
            "Epoch 16, Iteration 400, loss = 1.0126\n",
            "Epoch 16, Iteration 500, loss = 0.8097\n",
            "Epoch 16, Iteration 600, loss = 0.8328\n",
            "Epoch 16, Iteration 700, loss = 1.1858\n",
            "validation accuracy on validation set: 61.89326095581055\n",
            "Epoch 17, Iteration 0, loss = 0.9706\n",
            "Epoch 17, Iteration 100, loss = 0.9525\n",
            "Epoch 17, Iteration 200, loss = 0.9145\n",
            "Epoch 17, Iteration 300, loss = 0.9611\n",
            "Epoch 17, Iteration 400, loss = 0.9260\n",
            "Epoch 17, Iteration 500, loss = 0.9209\n",
            "Epoch 17, Iteration 600, loss = 1.0324\n",
            "Epoch 17, Iteration 700, loss = 1.2204\n",
            "validation accuracy on validation set: 62.714080810546875\n",
            "Epoch 18, Iteration 0, loss = 0.8459\n",
            "Epoch 18, Iteration 100, loss = 1.1250\n",
            "Epoch 18, Iteration 200, loss = 0.7668\n",
            "Epoch 18, Iteration 300, loss = 1.0859\n",
            "Epoch 18, Iteration 400, loss = 1.2818\n",
            "Epoch 18, Iteration 500, loss = 1.0034\n",
            "Epoch 18, Iteration 600, loss = 0.9357\n",
            "Epoch 18, Iteration 700, loss = 0.8949\n",
            "validation accuracy on validation set: 61.871891021728516\n",
            "Epoch 19, Iteration 0, loss = 0.7924\n",
            "Epoch 19, Iteration 100, loss = 1.0048\n",
            "Epoch 19, Iteration 200, loss = 0.9506\n",
            "Epoch 19, Iteration 300, loss = 0.7089\n",
            "Epoch 19, Iteration 400, loss = 0.9090\n",
            "Epoch 19, Iteration 500, loss = 1.1312\n",
            "Epoch 19, Iteration 600, loss = 1.2103\n",
            "Epoch 19, Iteration 700, loss = 0.8572\n",
            "validation accuracy on validation set: 60.27308654785156\n",
            "Epoch 20, Iteration 0, loss = 0.8815\n",
            "Epoch 20, Iteration 100, loss = 0.9804\n",
            "Epoch 20, Iteration 200, loss = 0.6448\n",
            "Epoch 20, Iteration 300, loss = 1.1032\n",
            "Epoch 20, Iteration 400, loss = 1.0092\n",
            "Epoch 20, Iteration 500, loss = 0.9111\n",
            "Epoch 20, Iteration 600, loss = 0.8759\n",
            "Epoch 20, Iteration 700, loss = 0.7929\n",
            "validation accuracy on validation set: 64.7554702758789\n",
            "Epoch 21, Iteration 0, loss = 0.9494\n",
            "Epoch 21, Iteration 100, loss = 0.7922\n",
            "Epoch 21, Iteration 200, loss = 1.0915\n",
            "Epoch 21, Iteration 300, loss = 0.9159\n",
            "Epoch 21, Iteration 400, loss = 0.7914\n",
            "Epoch 21, Iteration 500, loss = 0.9385\n",
            "Epoch 21, Iteration 600, loss = 1.1004\n",
            "Epoch 21, Iteration 700, loss = 0.9394\n",
            "validation accuracy on validation set: 63.15294647216797\n",
            "Epoch 22, Iteration 0, loss = 0.8041\n",
            "Epoch 22, Iteration 100, loss = 1.0545\n",
            "Epoch 22, Iteration 200, loss = 0.9436\n",
            "Epoch 22, Iteration 300, loss = 1.1579\n",
            "Epoch 22, Iteration 400, loss = 0.9367\n",
            "Epoch 22, Iteration 500, loss = 0.9029\n",
            "Epoch 22, Iteration 600, loss = 0.9750\n",
            "Epoch 22, Iteration 700, loss = 0.8036\n",
            "validation accuracy on validation set: 64.40505981445312\n",
            "Epoch 23, Iteration 0, loss = 0.8012\n",
            "Epoch 23, Iteration 100, loss = 0.8147\n",
            "Epoch 23, Iteration 200, loss = 0.7355\n",
            "Epoch 23, Iteration 300, loss = 0.8850\n",
            "Epoch 23, Iteration 400, loss = 0.9169\n",
            "Epoch 23, Iteration 500, loss = 0.9956\n",
            "Epoch 23, Iteration 600, loss = 0.8735\n",
            "Epoch 23, Iteration 700, loss = 0.8882\n",
            "validation accuracy on validation set: 65.71464538574219\n",
            "Epoch 24, Iteration 0, loss = 0.8809\n",
            "Epoch 24, Iteration 100, loss = 0.6778\n",
            "Epoch 24, Iteration 200, loss = 0.9521\n",
            "Epoch 24, Iteration 300, loss = 0.9782\n",
            "Epoch 24, Iteration 400, loss = 0.9875\n",
            "Epoch 24, Iteration 500, loss = 0.7196\n",
            "Epoch 24, Iteration 600, loss = 0.9106\n",
            "Epoch 24, Iteration 700, loss = 0.8668\n",
            "validation accuracy on validation set: 65.99702453613281\n",
            "Epoch 25, Iteration 0, loss = 0.7290\n",
            "Epoch 25, Iteration 100, loss = 0.7427\n",
            "Epoch 25, Iteration 200, loss = 0.7502\n",
            "Epoch 25, Iteration 300, loss = 0.8795\n",
            "Epoch 25, Iteration 400, loss = 0.8401\n",
            "Epoch 25, Iteration 500, loss = 0.8346\n",
            "Epoch 25, Iteration 600, loss = 1.0833\n",
            "Epoch 25, Iteration 700, loss = 0.7615\n",
            "validation accuracy on validation set: 66.0238265991211\n",
            "Epoch 26, Iteration 0, loss = 0.7652\n",
            "Epoch 26, Iteration 100, loss = 0.7768\n",
            "Epoch 26, Iteration 200, loss = 0.9989\n",
            "Epoch 26, Iteration 300, loss = 0.6713\n",
            "Epoch 26, Iteration 400, loss = 0.8473\n",
            "Epoch 26, Iteration 500, loss = 0.8906\n",
            "Epoch 26, Iteration 600, loss = 1.1306\n",
            "Epoch 26, Iteration 700, loss = 0.8194\n",
            "validation accuracy on validation set: 64.49478149414062\n",
            "Epoch 27, Iteration 0, loss = 0.8250\n",
            "Epoch 27, Iteration 100, loss = 0.7781\n",
            "Epoch 27, Iteration 200, loss = 0.9526\n",
            "Epoch 27, Iteration 300, loss = 0.6706\n",
            "Epoch 27, Iteration 400, loss = 0.9728\n",
            "Epoch 27, Iteration 500, loss = 0.6924\n",
            "Epoch 27, Iteration 600, loss = 0.7155\n",
            "Epoch 27, Iteration 700, loss = 0.7238\n",
            "validation accuracy on validation set: 66.4403305053711\n",
            "Epoch 28, Iteration 0, loss = 0.7772\n",
            "Epoch 28, Iteration 100, loss = 0.5442\n",
            "Epoch 28, Iteration 200, loss = 0.8307\n",
            "Epoch 28, Iteration 300, loss = 0.7738\n",
            "Epoch 28, Iteration 400, loss = 0.7597\n",
            "Epoch 28, Iteration 500, loss = 0.6508\n",
            "Epoch 28, Iteration 600, loss = 0.5126\n",
            "Epoch 28, Iteration 700, loss = 0.8537\n",
            "validation accuracy on validation set: 67.32186889648438\n",
            "Epoch 29, Iteration 0, loss = 0.7385\n",
            "Epoch 29, Iteration 100, loss = 1.0069\n",
            "Epoch 29, Iteration 200, loss = 0.9256\n",
            "Epoch 29, Iteration 300, loss = 0.7969\n",
            "Epoch 29, Iteration 400, loss = 0.6984\n",
            "Epoch 29, Iteration 500, loss = 0.7379\n",
            "Epoch 29, Iteration 600, loss = 0.7117\n",
            "Epoch 29, Iteration 700, loss = 0.6919\n",
            "validation accuracy on validation set: 66.0517578125\n",
            "Epoch 30, Iteration 0, loss = 0.8514\n",
            "Epoch 30, Iteration 100, loss = 0.9269\n",
            "Epoch 30, Iteration 200, loss = 0.8590\n",
            "Epoch 30, Iteration 300, loss = 0.6513\n",
            "Epoch 30, Iteration 400, loss = 0.5384\n",
            "Epoch 30, Iteration 500, loss = 0.7107\n",
            "Epoch 30, Iteration 600, loss = 0.5647\n",
            "Epoch 30, Iteration 700, loss = 0.8600\n",
            "validation accuracy on validation set: 69.76978302001953\n",
            "Epoch 31, Iteration 0, loss = 0.8784\n",
            "Epoch 31, Iteration 100, loss = 0.6280\n",
            "Epoch 31, Iteration 200, loss = 0.7585\n",
            "Epoch 31, Iteration 300, loss = 0.7218\n",
            "Epoch 31, Iteration 400, loss = 0.8693\n",
            "Epoch 31, Iteration 500, loss = 0.6896\n",
            "Epoch 31, Iteration 600, loss = 0.6823\n",
            "Epoch 31, Iteration 700, loss = 0.8311\n",
            "validation accuracy on validation set: 69.50704956054688\n",
            "Epoch 32, Iteration 0, loss = 0.6514\n",
            "Epoch 32, Iteration 100, loss = 0.5972\n",
            "Epoch 32, Iteration 200, loss = 0.4847\n",
            "Epoch 32, Iteration 300, loss = 0.5780\n",
            "Epoch 32, Iteration 400, loss = 0.5397\n",
            "Epoch 32, Iteration 500, loss = 0.5655\n",
            "Epoch 32, Iteration 600, loss = 0.6708\n",
            "Epoch 32, Iteration 700, loss = 0.7974\n",
            "validation accuracy on validation set: 70.67450714111328\n",
            "Epoch 33, Iteration 0, loss = 0.7276\n",
            "Epoch 33, Iteration 100, loss = 0.6522\n",
            "Epoch 33, Iteration 200, loss = 0.6828\n",
            "Epoch 33, Iteration 300, loss = 0.6627\n",
            "Epoch 33, Iteration 400, loss = 0.5546\n",
            "Epoch 33, Iteration 500, loss = 0.8159\n",
            "Epoch 33, Iteration 600, loss = 0.5553\n",
            "Epoch 33, Iteration 700, loss = 0.8698\n",
            "validation accuracy on validation set: 69.33995819091797\n",
            "Epoch 34, Iteration 0, loss = 0.6698\n",
            "Epoch 34, Iteration 100, loss = 0.6329\n",
            "Epoch 34, Iteration 200, loss = 0.6957\n",
            "Epoch 34, Iteration 300, loss = 0.5719\n",
            "Epoch 34, Iteration 400, loss = 0.8136\n",
            "Epoch 34, Iteration 500, loss = 0.5603\n",
            "Epoch 34, Iteration 600, loss = 0.6204\n",
            "Epoch 34, Iteration 700, loss = 0.6164\n",
            "validation accuracy on validation set: 67.29911804199219\n",
            "Epoch 35, Iteration 0, loss = 0.7798\n",
            "Epoch 35, Iteration 100, loss = 0.5570\n",
            "Epoch 35, Iteration 200, loss = 0.6409\n",
            "Epoch 35, Iteration 300, loss = 0.5147\n",
            "Epoch 35, Iteration 400, loss = 0.6303\n",
            "Epoch 35, Iteration 500, loss = 0.7751\n",
            "Epoch 35, Iteration 600, loss = 0.4551\n",
            "Epoch 35, Iteration 700, loss = 0.6320\n",
            "validation accuracy on validation set: 67.3871841430664\n",
            "Epoch 36, Iteration 0, loss = 0.8252\n",
            "Epoch 36, Iteration 100, loss = 0.7499\n",
            "Epoch 36, Iteration 200, loss = 0.7351\n",
            "Epoch 36, Iteration 300, loss = 0.5463\n",
            "Epoch 36, Iteration 400, loss = 0.6291\n",
            "Epoch 36, Iteration 500, loss = 0.5893\n",
            "Epoch 36, Iteration 600, loss = 0.7247\n",
            "Epoch 36, Iteration 700, loss = 0.6346\n",
            "validation accuracy on validation set: 71.5036849975586\n",
            "Epoch 37, Iteration 0, loss = 0.7107\n",
            "Epoch 37, Iteration 100, loss = 0.6621\n",
            "Epoch 37, Iteration 200, loss = 0.6360\n",
            "Epoch 37, Iteration 300, loss = 0.8206\n",
            "Epoch 37, Iteration 400, loss = 0.8078\n",
            "Epoch 37, Iteration 500, loss = 0.5092\n",
            "Epoch 37, Iteration 600, loss = 0.7945\n",
            "Epoch 37, Iteration 700, loss = 0.7119\n",
            "validation accuracy on validation set: 70.2850570678711\n",
            "Epoch 38, Iteration 0, loss = 0.4978\n",
            "Epoch 38, Iteration 100, loss = 0.6954\n",
            "Epoch 38, Iteration 200, loss = 0.6171\n",
            "Epoch 38, Iteration 300, loss = 0.4967\n",
            "Epoch 38, Iteration 400, loss = 0.6316\n",
            "Epoch 38, Iteration 500, loss = 0.5494\n",
            "Epoch 38, Iteration 600, loss = 0.6018\n",
            "Epoch 38, Iteration 700, loss = 0.8309\n",
            "validation accuracy on validation set: 70.37345886230469\n",
            "Epoch 39, Iteration 0, loss = 0.6118\n",
            "Epoch 39, Iteration 100, loss = 0.4540\n",
            "Epoch 39, Iteration 200, loss = 0.6064\n",
            "Epoch 39, Iteration 300, loss = 0.5878\n",
            "Epoch 39, Iteration 400, loss = 0.6440\n",
            "Epoch 39, Iteration 500, loss = 0.5583\n",
            "Epoch 39, Iteration 600, loss = 0.6886\n",
            "Epoch 39, Iteration 700, loss = 0.4554\n",
            "validation accuracy on validation set: 72.04444885253906\n",
            "Epoch 40, Iteration 0, loss = 0.5106\n",
            "Epoch 40, Iteration 100, loss = 0.7199\n",
            "Epoch 40, Iteration 200, loss = 0.6847\n",
            "Epoch 40, Iteration 300, loss = 0.5343\n",
            "Epoch 40, Iteration 400, loss = 0.5186\n",
            "Epoch 40, Iteration 500, loss = 0.6850\n",
            "Epoch 40, Iteration 600, loss = 0.5499\n",
            "Epoch 40, Iteration 700, loss = 0.7039\n",
            "validation accuracy on validation set: 72.26160430908203\n",
            "Epoch 41, Iteration 0, loss = 0.4329\n",
            "Epoch 41, Iteration 100, loss = 0.6142\n",
            "Epoch 41, Iteration 200, loss = 0.6497\n",
            "Epoch 41, Iteration 300, loss = 0.6241\n",
            "Epoch 41, Iteration 400, loss = 0.5482\n",
            "Epoch 41, Iteration 500, loss = 0.5091\n",
            "Epoch 41, Iteration 600, loss = 0.5731\n",
            "Epoch 41, Iteration 700, loss = 0.5805\n",
            "validation accuracy on validation set: 70.91441345214844\n",
            "Epoch 42, Iteration 0, loss = 0.6818\n",
            "Epoch 42, Iteration 100, loss = 0.6627\n",
            "Epoch 42, Iteration 200, loss = 0.5564\n",
            "Epoch 42, Iteration 300, loss = 0.4484\n",
            "Epoch 42, Iteration 400, loss = 0.4787\n",
            "Epoch 42, Iteration 500, loss = 0.4506\n",
            "Epoch 42, Iteration 600, loss = 0.7430\n",
            "Epoch 42, Iteration 700, loss = 0.6138\n",
            "validation accuracy on validation set: 70.2159194946289\n",
            "Epoch 43, Iteration 0, loss = 0.5252\n",
            "Epoch 43, Iteration 100, loss = 0.4358\n",
            "Epoch 43, Iteration 200, loss = 0.5883\n",
            "Epoch 43, Iteration 300, loss = 0.5933\n",
            "Epoch 43, Iteration 400, loss = 0.5512\n",
            "Epoch 43, Iteration 500, loss = 0.5852\n",
            "Epoch 43, Iteration 600, loss = 0.6463\n",
            "Epoch 43, Iteration 700, loss = 0.7739\n",
            "validation accuracy on validation set: 72.39216613769531\n",
            "Epoch 44, Iteration 0, loss = 0.5817\n",
            "Epoch 44, Iteration 100, loss = 0.4326\n",
            "Epoch 44, Iteration 200, loss = 0.3568\n",
            "Epoch 44, Iteration 300, loss = 0.6378\n",
            "Epoch 44, Iteration 400, loss = 0.4589\n",
            "Epoch 44, Iteration 500, loss = 0.4457\n",
            "Epoch 44, Iteration 600, loss = 0.7736\n",
            "Epoch 44, Iteration 700, loss = 0.7375\n",
            "validation accuracy on validation set: 71.2704086303711\n",
            "Epoch 45, Iteration 0, loss = 0.5071\n",
            "Epoch 45, Iteration 100, loss = 0.3118\n",
            "Epoch 45, Iteration 200, loss = 0.5227\n",
            "Epoch 45, Iteration 300, loss = 0.4981\n",
            "Epoch 45, Iteration 400, loss = 0.5805\n",
            "Epoch 45, Iteration 500, loss = 0.6067\n",
            "Epoch 45, Iteration 600, loss = 0.5885\n",
            "Epoch 45, Iteration 700, loss = 0.4752\n",
            "validation accuracy on validation set: 72.06060028076172\n",
            "Epoch 46, Iteration 0, loss = 0.5188\n",
            "Epoch 46, Iteration 100, loss = 0.4122\n",
            "Epoch 46, Iteration 200, loss = 0.5308\n",
            "Epoch 46, Iteration 300, loss = 0.4156\n",
            "Epoch 46, Iteration 400, loss = 0.6766\n",
            "Epoch 46, Iteration 500, loss = 0.5526\n",
            "Epoch 46, Iteration 600, loss = 0.5034\n",
            "Epoch 46, Iteration 700, loss = 0.4977\n",
            "validation accuracy on validation set: 71.86925506591797\n",
            "Epoch 47, Iteration 0, loss = 0.3835\n",
            "Epoch 47, Iteration 100, loss = 0.4103\n",
            "Epoch 47, Iteration 200, loss = 0.4374\n",
            "Epoch 47, Iteration 300, loss = 0.5130\n",
            "Epoch 47, Iteration 400, loss = 0.5881\n",
            "Epoch 47, Iteration 500, loss = 0.8482\n",
            "Epoch 47, Iteration 600, loss = 0.4906\n",
            "Epoch 47, Iteration 700, loss = 0.6509\n",
            "validation accuracy on validation set: 72.5717544555664\n",
            "Epoch 48, Iteration 0, loss = 0.4673\n",
            "Epoch 48, Iteration 100, loss = 0.6150\n",
            "Epoch 48, Iteration 200, loss = 0.6733\n",
            "Epoch 48, Iteration 300, loss = 0.3310\n",
            "Epoch 48, Iteration 400, loss = 0.6066\n",
            "Epoch 48, Iteration 500, loss = 0.4310\n",
            "Epoch 48, Iteration 600, loss = 0.5828\n",
            "Epoch 48, Iteration 700, loss = 0.5142\n",
            "validation accuracy on validation set: 72.93907928466797\n",
            "Epoch 49, Iteration 0, loss = 0.4384\n",
            "Epoch 49, Iteration 100, loss = 0.5344\n",
            "Epoch 49, Iteration 200, loss = 0.5730\n",
            "Epoch 49, Iteration 300, loss = 0.4874\n",
            "Epoch 49, Iteration 400, loss = 0.5865\n",
            "Epoch 49, Iteration 500, loss = 0.3611\n",
            "Epoch 49, Iteration 600, loss = 0.4170\n",
            "Epoch 49, Iteration 700, loss = 0.6631\n",
            "validation accuracy on validation set: 71.43714141845703\n",
            "Epoch 50, Iteration 0, loss = 0.5525\n",
            "Epoch 50, Iteration 100, loss = 0.5744\n",
            "Epoch 50, Iteration 200, loss = 0.5387\n",
            "Epoch 50, Iteration 300, loss = 0.4485\n",
            "Epoch 50, Iteration 400, loss = 0.4216\n",
            "Epoch 50, Iteration 500, loss = 0.6566\n",
            "Epoch 50, Iteration 600, loss = 0.5179\n",
            "Epoch 50, Iteration 700, loss = 0.3901\n",
            "validation accuracy on validation set: 73.27027130126953\n",
            "Epoch 51, Iteration 0, loss = 0.4624\n",
            "Epoch 51, Iteration 100, loss = 0.5113\n",
            "Epoch 51, Iteration 200, loss = 0.5416\n",
            "Epoch 51, Iteration 300, loss = 0.5303\n",
            "Epoch 51, Iteration 400, loss = 0.4220\n",
            "Epoch 51, Iteration 500, loss = 0.4890\n",
            "Epoch 51, Iteration 600, loss = 0.6473\n",
            "Epoch 51, Iteration 700, loss = 0.4832\n",
            "validation accuracy on validation set: 73.67618560791016\n",
            "Epoch 52, Iteration 0, loss = 0.6303\n",
            "Epoch 52, Iteration 100, loss = 0.2795\n",
            "Epoch 52, Iteration 200, loss = 0.4564\n",
            "Epoch 52, Iteration 300, loss = 0.4007\n",
            "Epoch 52, Iteration 400, loss = 0.3507\n",
            "Epoch 52, Iteration 500, loss = 0.7314\n",
            "Epoch 52, Iteration 600, loss = 0.6292\n",
            "Epoch 52, Iteration 700, loss = 0.4689\n",
            "validation accuracy on validation set: 74.07941436767578\n",
            "Epoch 53, Iteration 0, loss = 0.2731\n",
            "Epoch 53, Iteration 100, loss = 0.4221\n",
            "Epoch 53, Iteration 200, loss = 0.4605\n",
            "Epoch 53, Iteration 300, loss = 0.3503\n",
            "Epoch 53, Iteration 400, loss = 0.5037\n",
            "Epoch 53, Iteration 500, loss = 0.4194\n",
            "Epoch 53, Iteration 600, loss = 0.5384\n",
            "Epoch 53, Iteration 700, loss = 0.4563\n",
            "validation accuracy on validation set: 71.69888305664062\n",
            "Epoch 54, Iteration 0, loss = 0.3721\n",
            "Epoch 54, Iteration 100, loss = 0.3829\n",
            "Epoch 54, Iteration 200, loss = 0.4290\n",
            "Epoch 54, Iteration 300, loss = 0.3657\n",
            "Epoch 54, Iteration 400, loss = 0.4198\n",
            "Epoch 54, Iteration 500, loss = 0.5300\n",
            "Epoch 54, Iteration 600, loss = 0.4561\n",
            "Epoch 54, Iteration 700, loss = 0.6055\n",
            "validation accuracy on validation set: 73.0295639038086\n",
            "Epoch 55, Iteration 0, loss = 0.4124\n",
            "Epoch 55, Iteration 100, loss = 0.3775\n",
            "Epoch 55, Iteration 200, loss = 0.4388\n",
            "Epoch 55, Iteration 300, loss = 0.3484\n",
            "Epoch 55, Iteration 400, loss = 0.5446\n",
            "Epoch 55, Iteration 500, loss = 0.4608\n",
            "Epoch 55, Iteration 600, loss = 0.4982\n",
            "Epoch 55, Iteration 700, loss = 0.4539\n",
            "validation accuracy on validation set: 73.69483947753906\n",
            "Epoch 56, Iteration 0, loss = 0.3149\n",
            "Epoch 56, Iteration 100, loss = 0.2974\n",
            "Epoch 56, Iteration 200, loss = 0.4351\n",
            "Epoch 56, Iteration 300, loss = 0.5161\n",
            "Epoch 56, Iteration 400, loss = 0.4715\n",
            "Epoch 56, Iteration 500, loss = 0.3747\n",
            "Epoch 56, Iteration 600, loss = 0.4057\n",
            "Epoch 56, Iteration 700, loss = 0.2967\n",
            "validation accuracy on validation set: 73.15233612060547\n",
            "Epoch 57, Iteration 0, loss = 0.1990\n",
            "Epoch 57, Iteration 100, loss = 0.3331\n",
            "Epoch 57, Iteration 200, loss = 0.4099\n",
            "Epoch 57, Iteration 300, loss = 0.4878\n",
            "Epoch 57, Iteration 400, loss = 0.3263\n",
            "Epoch 57, Iteration 500, loss = 0.5180\n",
            "Epoch 57, Iteration 600, loss = 0.4094\n",
            "Epoch 57, Iteration 700, loss = 0.7068\n",
            "validation accuracy on validation set: 73.44819641113281\n",
            "Epoch 58, Iteration 0, loss = 0.3624\n",
            "Epoch 58, Iteration 100, loss = 0.3479\n",
            "Epoch 58, Iteration 200, loss = 0.6419\n",
            "Epoch 58, Iteration 300, loss = 0.5882\n",
            "Epoch 58, Iteration 400, loss = 0.3478\n",
            "Epoch 58, Iteration 500, loss = 0.2428\n",
            "Epoch 58, Iteration 600, loss = 0.4844\n",
            "Epoch 58, Iteration 700, loss = 0.4288\n",
            "validation accuracy on validation set: 73.95378875732422\n",
            "EARLY STOP DUE TO DECREASED VALIDATION ACCURACY: USING MODEL AT EPOCH 52\n",
            "best model validation accuracy: 74.07941436767578\n"
          ]
        }
      ],
      "source": [
        "model = myNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.0005, betas=(0.9,0.999))\n",
        "train(loader_train, loader_test, model, optimizer, \"seg_model\", epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval 7570501 / 10240000 correct (73.93)\n"
          ]
        }
      ],
      "source": [
        "test(loader_test, model, \"seg_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
